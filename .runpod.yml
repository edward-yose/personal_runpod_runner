name: vllm-gpt-oss-20b
description: vLLM inference for GPT-OSS-20B

# Docker configuration
docker:
  dockerfile: Dockerfile
  context: .
  
# Build arguments
build_args:
  - HF_TOKEN=${HF_TOKEN}

# Environment variables
env:
  HF_TOKEN: ${HF_TOKEN}
  VLLM_WORKER_MULTIPROC_METHOD: spawn
  CUDA_VISIBLE_DEVICES: "0"

# GPU configuration
gpu:
  type: "A40"  # or A100, RTX4090, etc.
  count: 1

# Resource limits
resources:
  cpu: 8
  memory: 32  # GB
  disk: 50    # GB

# Scaling configuration
scaling:
  min_workers: 0
  max_workers: 3
  idle_timeout: 300  # seconds

# Health check (optional but recommended)
health_check:
  endpoint: /health
  interval: 30
  timeout: 10
  retries: 3

# Handler configuration
handler:
  file: handler.py
  function: handler
  async: true  # Important for vLLM async engine